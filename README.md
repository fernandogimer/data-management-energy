# ‚ö° Data Management - Predicci√≥n de Demanda Energ√©tica en Barcelona

![Python](https://img.shields.io/badge/Python-3.9+-blue)
![BigQuery](https://img.shields.io/badge/BigQuery-Enabled-orange)
![Azure](https://img.shields.io/badge/Azure-Databricks-blue)
![Looker Studio](https://img.shields.io/badge/Looker_Studio-Visualization-yellow)

## üìã Descripci√≥n del Proyecto

Repositorio del proyecto de la asignatura Data Management.

**Objetivo:** Predecir y explicar la demanda energ√©tica en Barcelona integrando datos estructurados (BigQuery) y no estructurados / ML (Azure). Visualizaci√≥n en Looker Studio.

### Alcance del Proyecto

- Integrar CSV p√∫blicos de consumo (CP / sector / tramo horario, 2022‚Äì2025) en una tabla √∫nica particionada en BigQuery
- Enriquecer con contexto (meteo, festivos y eventos/alertas) para explicar picos
- Modelar (baseline + AutoML/ML en Azure) para mejorar la precisi√≥n frente a un baseline hist√≥rico
- Medir y comunicar mediante KPIs y dashboard

---

## üèóÔ∏è Arquitectura de Datos

### Capa de Almacenamiento (BigQuery)

**Estructurados (BigQuery):** Unificar 2022‚Äì2025 en `Data_Management.consumo_barcelona`

- **Partition by:** `fecha`
- **Cluster by:** `codigo_postal`, `sector_economico`

**Vistas BI/ML:**
- Generar vista para an√°lisis y ML

**Checks:** Nulos, negativos, duplicados y rangos

**Dashboard m√≠nimo:** Serie real vs. predicci√≥n, KPIs b√°sicos

**Iteraci√≥n siguiente:** Ingesti√≥n meteo/festivos/eventos + entrenamiento/AutoML en Azure

### Flujo de Datos

```
[CSV consumo BCN 2022‚Äì2025]
         ‚Üì
Google BigQuery (dataset: Data_Management)
         ‚Üì
(1) Tabla √∫nica: consumo_barcelona
    ‚Ä¢ Partition By: fecha (DATE)
    ‚Ä¢ Cluster By: codigo_postal, sector_economico
         ‚Üì
(2) Vistas:
    ‚Ä¢ vw_consumo_bcn_current (filtro calidad BI/ML)
         ‚Üì
(3) BI: Looker Studio
         ‚Üì
(4) Enriquecimiento (pr√≥xima fase):
    ‚Ä¢ Meteo (AEMET/Meteocat)
    ‚Ä¢ Festivos (ICS)
    ‚Ä¢ Eventos/alertas (Azure Logic Apps + Azure AI Text Analytics)
    ‚Ä¢ Joins en BigQuery
    ‚Ä¢ Entrenamiento/AutoML en Azure
    ‚Ä¢ Persistencia de predicciones
```

### Decisiones T√©cnicas Clave

- **Particionado por fecha** para optimizar coste y velocidad
- **Vistas estables** para no romper BI/ML al cambiar tablas base
- **Trazabilidad:** `anio_origen`, `load_ts`

---

## üìÅ Estructura del Repositorio

```
bq/
‚îú‚îÄ‚îÄ ddl/
‚îÇ   ‚îî‚îÄ‚îÄ 01_create_consumo_barcelona.sql  # CTAS que unifica 2022‚Äì2025 en tabla √∫nica
‚îú‚îÄ‚îÄ views/
‚îÇ   ‚îú‚îÄ‚îÄ vw_consumo_bcn_current.sql       # Vista con filtro b√°sico de calidad
‚îÇ   ‚îî‚îÄ‚îÄ vw_consumo_bcn_con_horas.sql     # (Opcional) Parseo de horas desde tramo_horario
‚îî‚îÄ‚îÄ checks/
    ‚îî‚îÄ‚îÄ checks_basicos.sql               # Nulos/negativos/duplicados + rangos

docs/
‚îî‚îÄ‚îÄ decisiones.md                        # Registro de cambios/decisiones (qu√©/por qu√©/cu√°ndo/qui√©n)
‚îî‚îÄ‚îÄ informe_pipeline_nlp.md             # Informe t√©cnico del pipeline NLP

notebooks/
‚îî‚îÄ‚îÄ databricks/
    ‚îî‚îÄ‚îÄ pipeline_databricks_nlp.py      # Pipeline de datos en Databricks

README.md
.gitignore
LICENSE
```

---

## üìä Esquema de Datos

### Tabla Principal: `consumo_barcelona`

**Partition By:** `fecha` (DATE) ¬∑ **Cluster By:** `codigo_postal`, `sector_economico`

| Columna | Tipo | Descripci√≥n |
|---------|------|-------------|
| `fecha` | DATE | Fecha del registro |
| `codigo_postal` | STRING | C√≥digo postal (5 d√≠gitos) |
| `sector_economico` | STRING | Sector econ√≥mico |
| `tramo_horario` | STRING | "De 00:00:00 a 06:00:00" / "No consta" |
| `kwh` | FLOAT64 | Consumo del tramo en kWh |
| `anio_origen` | STRING | A√±o/origen del registro (p. ej., "2023") |
| `load_ts` | TIMESTAMP | Timestamp de carga/transformaci√≥n |

### Vistas Disponibles

- **`vw_consumo_bcn_current`**: Excluye "No consta" y kWh nulos/negativos
- **`vw_consumo_bcn_con_horas`**: Extrae `hora_ini` / `hora_fin`

---

## üöÄ C√≥mo Usar Este Proyecto

### Requisitos Previos

- Acceso a Google BigQuery
- Looker Studio
- Azure Databricks (para el pipeline NLP)
- Python 3.9+

### Pasos de Implementaci√≥n

1. **Ejecuta en BigQuery:**
   ```sql
   -- Ejecutar los scripts en orden:
   bq/ddl/01_create_consumo_barcelona.sql
   ```

2. **Conecta Looker Studio:**
   - Conectar a la vista `vw_consumo_bcn_current`

3. **Verifica la calidad de datos:**
   ```sql
   -- Ejecutar checks
   bq/checks/checks_basicos.sql
   ```

---

## üìà KPIs y Calidad de Datos

### M√©tricas de Calidad

- **Completitud:** `kwh` no nulo ‚â• 99%
- **Validez:** `kwh` ‚â• 0; `fecha` en rango dataset
- **Unicidad l√≥gica:** (`fecha`, `codigo_postal`, `tramo_horario`, `sector_economico`) sin duplicados
- **Trazabilidad:** `anio_origen`, `load_ts`

### KPIs del Proyecto

- Error medio absoluto (MAE) de predicci√≥n
- Cobertura de datos por c√≥digo postal
- Porcentaje de datos validados
- Tiempo de actualizaci√≥n del pipeline

---

## ü§ñ Pipeline NLP en Azure Databricks

Como parte del proceso de ingesta de datos, se desarroll√≥ un pipeline de datos independiente en Azure Databricks para generar y enriquecer una de las fuentes de datos.

- **Objetivo:** Demostrar la orquestaci√≥n de un pipeline end-to-end en Databricks, incluyendo la simulaci√≥n de datos, el enriquecimiento con una API de IA Generativa (Google Gemini) y la exportaci√≥n de resultados a BigQuery.
- **Tecnolog√≠as:** Azure Databricks, Python (PySpark, Pandas), Google Gemini API.
- **Resultado:** La tabla `bronze_data.precios_actividad_nlp_manual` en BigQuery.
- **Detalles:** Ver el [informe t√©cnico completo](docs/informe_pipeline_nlp.md) y el [c√≥digo del notebook](notebooks/databricks/pipeline_databricks_nlp.py).

---

## üõ†Ô∏è Tecnolog√≠as Utilizadas

- **Cloud & Data Warehouse:** Google BigQuery
- **Procesamiento:** Azure Databricks, PySpark
- **Visualizaci√≥n:** Looker Studio
- **IA Generativa:** Google Gemini API
- **Lenguajes:** Python, SQL
- **Control de versiones:** Git, GitHub

---

## üë• Autores

**Fernando Gimenez** - *Desarrollo y documentaci√≥n*  
**Julio Clavijo** - julio.clavijo88@gmail.com  
**Miguel Roces** - miguelrocesdiaz@gmail.com

**Asignatura:** Data Management  
**Fecha:** Octubre 2025

---

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para m√°s detalles.

---

## üìû Contacto

Si tienes preguntas sobre este proyecto, puedes contactarnos a trav√©s de:
- GitHub: [@fernandogimer](https://github.com/fernandogimer)
- Julio Clavijo: julio.clavijo88@gmail.com
- Miguel Roces: miguelrocesdiaz@gmail.com

---

## üôè Agradecimientos

- Datos de consumo energ√©tico proporcionados por fuentes p√∫blicas de Barcelona
- Asignatura Data Management por la gu√≠a del proyecto
