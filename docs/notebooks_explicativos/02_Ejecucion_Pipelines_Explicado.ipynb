{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "627974cc",
   "metadata": {},
   "source": [
    "# Notebook 2: Guía de Ejecución de los Pipelines de ML\n",
    "\n",
    "**Objetivo:** Este notebook documenta el propósito y el uso de los dos scripts principales de Python que conforman el pipeline de Machine Learning: `train_model_final.py` y `batch_prediction.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5da410",
   "metadata": {},
   "source": [
    "Pipeline de Entrenamiento: train_model_final.py\n",
    "Propósito: Este script es el corazón del proyecto. Su función es entrenar los tres modelos de predicción (uno por cada sector económico) y guardarlos para su uso posterior.\n",
    "\n",
    "Pasos que realiza:\n",
    "\n",
    "1. Carga los datos completos desde la tabla gold_data.modelo_final_v2 de BigQuery.\n",
    "2. Inicia un bucle para tratar cada sector (Industrial, Residencial, Servicios) de forma independiente.\n",
    "3. Aplica la Ingeniería de Características Avanzada: Crea lags horarios, diarios y características no lineales para cada subconjunto de datos.\n",
    "4. Realiza una División Cronológica: Separa los datos en un 80% para entrenamiento y un 20% para prueba, simulando un escenario real.\n",
    "5. Entrena un modelo XGBoost especializado para ese sector.\n",
    "6. Evalúa el rendimiento del modelo y muestra el MAPE en la consola.\n",
    "7. Genera un gráfico SHAP para visualizar la importancia de las características de ese modelo.\n",
    "8. Al final, guarda los tres modelos entrenados en un único archivo: modelos_entrenados_por_sector.pkl.\n",
    "\n",
    "Para ejecutarlo: Abre una terminal, activa el entorno de Anaconda (conda activate .venv) y ejecuta: python python/src/train_model_final.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36738554",
   "metadata": {},
   "source": [
    "## 2. Pipeline de Predicción por Lotes: `batch_prediction.py`\n",
    "\n",
    "**Propósito:** Este script utiliza los modelos ya entrenados para generar predicciones sobre un conjunto de datos completo y almacenar los resultados.\n",
    "\n",
    "**Pasos que realiza:**\n",
    "1.  **Carga los tres modelos** desde el archivo `modelos_entrenados_por_sector.pkl`.\n",
    "2.  **Carga el 100% de los datos** desde la tabla `gold_data.modelo_final_v2`.\n",
    "3.  **Inicia un bucle** por cada sector, aplicando la misma **Ingeniería de Características** que se usó en el entrenamiento para asegurar la consistencia.\n",
    "4.  **Aplica el modelo correspondiente** a cada fila para generar una predicción.\n",
    "5.  **Añade las predicciones** en una nueva columna llamada `consumo_kwh_predicho`.\n",
    "6.  **Une los resultados** de los tres sectores.\n",
    "7.  **Crea (o reemplaza) una nueva tabla** en BigQuery llamada `gold_data.predicciones_modelo_final` con los resultados, incluyendo tanto el consumo real como el predicho.\n",
    "\n",
    "**Para ejecutarlo:** (Asegúrate de haber ejecutado primero el script de entrenamiento)\n",
    "\n",
    "python python/src/batch_prediction.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
