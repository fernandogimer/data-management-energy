{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a692a49e",
   "metadata": {},
   "source": [
    "# Análisis del Pipeline de Entrenamiento del Modelo\n",
    "\n",
    "**Autor:** Julio Clavijo\n",
    "**Fecha:** 23/10/2025\n",
    "\n",
    "## Objetivo\n",
    "Este notebook documenta y ejecuta el pipeline de entrenamiento del modelo de Machine Learning para la predicción de la demanda energética en Barcelona. El proceso completo, desde la carga de datos hasta la interpretación del modelo, se detalla a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837c9899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 0. IMPORTACIÓN DE LIBRERÍAS ---\n",
    "# Se importan todas las herramientas necesarias para el análisis.\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from google.oauth2 import service_account\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "print(\"Librerías importadas con éxito.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68ecb9c",
   "metadata": {},
   "source": [
    "## Paso 1: Carga de Datos desde BigQuery\n",
    "\n",
    "Nos conectamos a nuestro Data Warehouse en BigQuery para cargar la tabla `gold_data.modelo_final`. Esta tabla es el resultado de todo el pipeline de ETL y contiene los datos limpios, unidos y listos para el modelado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc6f7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. CARGA DE DATOS DESDE BIGQUERY ---\n",
    "print(\"--- Iniciando el pipeline de entrenamiento de modelo ---\")\n",
    "print(\"Paso 1: Cargando datos desde la tabla Gold 'modelo_final'...\")\n",
    "\n",
    "# Carga las variables de entorno para la autenticación\n",
    "load_dotenv()\n",
    "GCP_KEY_PATH = os.getenv(\"GCP_SERVICE_ACCOUNT_KEY_PATH\")\n",
    "PROJECT_ID = \"datamanagementbi\"\n",
    "TABLE_ID = \"gold_data.modelo_final\"\n",
    "\n",
    "# Autenticación y ejecución de la consulta\n",
    "try:\n",
    "    credentials = service_account.Credentials.from_service_account_file(GCP_KEY_PATH)\n",
    "    query = f\"SELECT * FROM `{PROJECT_ID}.{TABLE_ID}` ORDER BY fecha, id_tramo_horario\"\n",
    "    df = pd.read_gbq(query, project_id=PROJECT_ID, credentials=credentials, progress_bar_type=None)\n",
    "    print(f\"Carga de datos completada. Se han cargado {len(df)} registros.\")\n",
    "    display(df.head()) # Mostramos las primeras 5 filas para verificar\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar datos desde BigQuery: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2d65bd",
   "metadata": {},
   "source": [
    "## Paso 2: Preparación de Datos y Feature Engineering\n",
    "\n",
    "Realizamos los últimos ajustes al DataFrame:\n",
    "1.  Aseguramos que la columna `fecha` sea de tipo `datetime` y la establecemos como el índice de la tabla. Esto es fundamental para trabajar con series temporales.\n",
    "2.  Convertimos las columnas de IDs y nombres categóricos al tipo `category` de Pandas. Esto optimiza el uso de memoria y es la forma correcta de indicar a librerías como XGBoost que estas columnas son etiquetas, no valores numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a9a2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. PREPARACIÓN DE DATOS Y FEATURE ENGINEERING ---\n",
    "print(\"\\nPaso 2: Preparando datos para el entrenamiento...\")\n",
    "df['fecha'] = pd.to_datetime(df['fecha'])\n",
    "df.set_index('fecha', inplace=True)\n",
    "\n",
    "categorical_cols = [\n",
    "    'id_geografia', 'id_tramo_horario', 'id_sector_economico', \n",
    "    'dia_de_la_semana_nombre', 'nombre_barrio', 'nombre_distrito'\n",
    "]\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype('category')\n",
    "print(\"Tipos de datos preparados y columnas categóricas configuradas.\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab86fee",
   "metadata": {},
   "source": [
    "## Paso 3 y 4: Selección de Features y División de Datos\n",
    "\n",
    "Separamos nuestro conjunto de datos en:\n",
    "- **Target (`y`):** La variable que queremos predecir (`consumo_kwh`).\n",
    "- **Features (`X`):** Todas las \"pistas\" que usará el modelo para hacer la predicción.\n",
    "\n",
    "Luego, dividimos los datos de forma **cronológica**. Usamos el 80% más antiguo para entrenar y reservamos el 20% más reciente para evaluar el modelo, simulando un escenario de predicción real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfeb626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. SELECCIÓN DE CARACTERÍSTICAS Y OBJETIVO ---\n",
    "target = 'consumo_kwh'\n",
    "features = [col for col in df.columns if col not in [\n",
    "    target, 'nombre_municipio', 'festivo_descripcion'\n",
    "]]\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# --- 4. DIVISIÓN DE DATOS (TRAIN/TEST SPLIT PARA SERIES TEMPORALES) ---\n",
    "test_size = int(len(df) * 0.2)\n",
    "X_train, X_test = X[:-test_size], X[-test_size:]\n",
    "y_train, y_test = y[:-test_size], y[-test_size:]\n",
    "print(f\"Datos divididos: {len(X_train)} para entrenamiento, {len(X_test)} para prueba.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3021cab9",
   "metadata": {},
   "source": [
    "## Paso 5 y 6: Entrenamiento y Evaluación del Modelo\n",
    "\n",
    "Utilizamos **XGBoost**, un potente algoritmo de Gradient Boosting, para entrenar nuestro modelo de regresión.\n",
    "- **Entrenamiento:** El modelo aprende los patrones a partir del conjunto `_train`. Usamos `early_stopping_rounds` para evitar el sobreajuste y optimizar el tiempo de entrenamiento.\n",
    "- **Evaluación:** Medimos el rendimiento del modelo sobre el conjunto `_test` (datos que nunca ha visto) usando la métrica **MAPE** (Mean Absolute Percentage Error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80d9c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. ENTRENAMIENTO DEL MODELO XGBOOST ---\n",
    "print(\"\\nPaso 5: Entrenando el modelo XGBoost...\")\n",
    "model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=8,\n",
    "    early_stopping_rounds=10,\n",
    "    eval_metric='mape',\n",
    "    enable_categorical=True\n",
    ")\n",
    "model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
    "print(\"Modelo entrenado con éxito.\")\n",
    "\n",
    "# --- 6. EVALUACIÓN DEL MODELO ---\n",
    "print(\"\\nPaso 6: Evaluando el rendimiento del modelo...\")\n",
    "y_pred = model.predict(X_test)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "print(\"=\"*50)\n",
    "print(f\"  RESULTADO FINAL -> MAPE: {mape:.4f}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7af2ab",
   "metadata": {},
   "source": [
    "## Paso 7: Interpretación del Modelo (SHAP)\n",
    "\n",
    "Finalmente, utilizamos la librería **SHAP (SHapley Additive exPlanations)** para entender qué características han sido más importantes para las predicciones del modelo. Esto nos permite \"abrir la caja negra\" y explicar por qué el modelo toma ciertas decisiones.\n",
    "\n",
    "El siguiente gráfico muestra la importancia media de cada característica. Una barra más larga indica un mayor impacto en la predicción del consumo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e144a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. INTERPRETACIÓN DEL MODELO (SHAP) ---\n",
    "print(\"\\nPaso 7: Generando gráfico de importancia de características (SHAP)...\")\n",
    "\n",
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer(X_test, check_additivity=False)\n",
    "\n",
    "# Generamos y mostramos el gráfico\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "shap.summary_plot(shap_values, X_test, show=False, plot_type=\"bar\", ax=ax)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Guardamos la figura\n",
    "output_path = os.path.join(os.getcwd(), 'shap_summary_final.png')\n",
    "fig.savefig(output_path)\n",
    "plt.close(fig)\n",
    "print(f\"Gráfico guardado con éxito en: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
